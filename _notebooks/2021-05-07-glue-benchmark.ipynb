{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blogpost_glue_benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5852291e134949609f1522503b45205d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e6487bc5a6544e0944be2beb010ba04",
              "IPY_MODEL_1f59dc31d2fd45cd8bfdc6d3f38ebfb4"
            ],
            "layout": "IPY_MODEL_0fa01ff7fe3d432d8afa6806e53196df"
          }
        },
        "0fa01ff7fe3d432d8afa6806e53196df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e6487bc5a6544e0944be2beb010ba04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "#0: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f726ec197e184e948d40ea14e0ba41c3",
            "max": 34111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb4ef3b18bff4486b8871997654ec852",
            "value": 34111
          }
        },
        "1f59dc31d2fd45cd8bfdc6d3f38ebfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d508a1d47d304ed8821e38038e06cc72",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0eed7e356218453795d79bd17b31d21b",
            "value": " 34111/34111 [00:06&lt;00:00, 4909.52ex/s]"
          }
        },
        "cb4ef3b18bff4486b8871997654ec852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f726ec197e184e948d40ea14e0ba41c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eed7e356218453795d79bd17b31d21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d508a1d47d304ed8821e38038e06cc72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7715ffd7e424886a431dd79b3c8ba31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90fde3947574cfabea146e198977ddc",
              "IPY_MODEL_c05a677847ba423caa8e23a655949308"
            ],
            "layout": "IPY_MODEL_89155e81544d4e49ba737cba6f9b4f99"
          }
        },
        "89155e81544d4e49ba737cba6f9b4f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90fde3947574cfabea146e198977ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "#1: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091e08fa4b8d43cca0cfce9bcc9a6f67",
            "max": 34110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99ab02879ee64d60a4c3b63c8b183eb8",
            "value": 34110
          }
        },
        "c05a677847ba423caa8e23a655949308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cae5a2e066d4a34b837a94958a14187",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e91a2643019e43f89fa414a5ae21c517",
            "value": " 34110/34110 [00:07&lt;00:00, 4803.13ex/s]"
          }
        },
        "99ab02879ee64d60a4c3b63c8b183eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "091e08fa4b8d43cca0cfce9bcc9a6f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91a2643019e43f89fa414a5ae21c517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cae5a2e066d4a34b837a94958a14187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZGfclrLI_1",
        "outputId": "edf40b38-7684-4b49-cf3b-de46bd46f064"
      },
      "source": [
        "# hide\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  7 09:40:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "lcwsNaUMLJAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcfbac3-2081-477a-ee43-9a34aa211fe4"
      },
      "source": [
        "# hide\n",
        "import sys\n",
        "if 'google.colab' in sys.modules: \n",
        "    !pip install -Uqq fastai transformers datasets wandb\n",
        "    !pip install -q git+git://github.com/aikindergarten/fasthugs.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 4.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 5.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225kB 22.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 17.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 38.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 40.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 46.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 45.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 43.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 35.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 10.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.7MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fasthugs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "Bcz3wDvmLJAE"
      },
      "source": [
        "# Finetuning Transformers on GLUE benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "0Y4s0buwLJAF"
      },
      "source": [
        "#collapse_input\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from fastai.text.all import *\n",
        "from fastai.callback.wandb import *\n",
        "\n",
        "from fasthugs.learner import TransLearner\n",
        "from fasthugs.data import TransformersTextBlock, TextGetter, get_splits\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "import wandb\n",
        "import gc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mySHLBZs6WL4",
        "outputId": "18975bbe-679f-4abc-a84b-866699a773f3"
      },
      "source": [
        "#hide\n",
        "%env WANDB_ENTITY=fastai_community\n",
        "%env WANDB_PROJECT=glue-benchmark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: WANDB_ENTITY=fastai_community\n",
            "env: WANDB_PROJECT=glue-benchmark\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "7E8pkNHq6WL5"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this blogpost will look at how to conbine the power of HuggingFace with great flexibility of fastai. For this purpose we will look at finetuning on [GLUE benchmark](https://gluebenchmark.com/) tasks. Fun fact: it was introduced in this [paper](https://arxiv.org/abs/1804.07461) 2018 as tough to beat benchmark to chellange NLP systems and in just about a year new [SuperGLUE](https://arxiv.org/abs/1911.11763) benchmark was introduced because original GLUE has become too easy for the models.\n",
        "\n",
        "To give you a grasp on what are we dealing with, here is a brief summary of GLUE tasks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EQ_j3Tc-6WL5",
        "outputId": "5008e258-1665-4b67-f8f9-a37fa239f42d"
      },
      "source": [
        "#hide_input\n",
        "abreviations=[\"cola\",\"sst2\",\"mrpc\",\"stsb\",\"qqp\",\"mnli\",\"qnli\",\"rte\",\"wnli\"]\n",
        "name = [\n",
        "    \"Corpus of Linguistic Acceptability\",\n",
        "    \"Stanford Sentiment Treebank\",\n",
        "    \"Microsoft Research Paraphrase Corpus\",\n",
        "    \"Semantic Textual Similarity Benchmark\",\n",
        "    \"Quora question pair\",\n",
        "    \"Mulit-Genre Natural Language Inference\",\n",
        "    \"Stanford Question Answering Dataset\",\n",
        "    \"Recognize Textual Entailment\",\n",
        "    \"Winograd Schema Challenge\"\n",
        "]\n",
        "descriptions = [\n",
        "    \"Determine whether it is a grammatical sentence\",\n",
        "    \"Predict the sentiment of a givensentence\",\n",
        "    \"Determine whether the sentences in the pair are semantically equivalent\",\n",
        "    \"Determine similarity score for 2 sentences\",\n",
        "    \"Determine if 2 questions are the same (paraphrase)\",\n",
        "    \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
        "    \"Determine whether the context sentence containsthe answer to the question\",\n",
        "    \"Determine whether one sentece entails another\",\n",
        "    \"Predict if the sentence with the pronoun substituted is entailed by the original sentence\"\n",
        "]\n",
        "df = pd.DataFrame({'Name':name,\n",
        "                   'Task description':descriptions,\n",
        "                   'Size':['8.5k','67k','3.7k','7k','364k','393k','105k','2.5k', '634'],\n",
        "                   'Metrics':['matthews_corrcoef','accuracy','f1/accuracy','pearsonr/spearmanr',\n",
        "                              'f1/accuracy','accuracy','accuracy','accuracy','accuracy']},\n",
        "                   index=abreviations)\n",
        "display_df(df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Task description</th>\n",
              "      <th>Size</th>\n",
              "      <th>Metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cola</th>\n",
              "      <td>Corpus of Linguistic Acceptability</td>\n",
              "      <td>Determine whether it is a grammatical sentence</td>\n",
              "      <td>8.5k</td>\n",
              "      <td>matthews_corrcoef</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sst2</th>\n",
              "      <td>Stanford Sentiment Treebank</td>\n",
              "      <td>Predict the sentiment of a givensentence</td>\n",
              "      <td>67k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mrpc</th>\n",
              "      <td>Microsoft Research Paraphrase Corpus</td>\n",
              "      <td>Determine whether the sentences in the pair are semantically equivalent</td>\n",
              "      <td>3.7k</td>\n",
              "      <td>f1/accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stsb</th>\n",
              "      <td>Semantic Textual Similarity Benchmark</td>\n",
              "      <td>Determine similarity score for 2 sentences</td>\n",
              "      <td>7k</td>\n",
              "      <td>pearsonr/spearmanr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qqp</th>\n",
              "      <td>Quora question pair</td>\n",
              "      <td>Determine if 2 questions are the same (paraphrase)</td>\n",
              "      <td>364k</td>\n",
              "      <td>f1/accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mnli</th>\n",
              "      <td>Mulit-Genre Natural Language Inference</td>\n",
              "      <td>Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
              "      <td>393k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qnli</th>\n",
              "      <td>Stanford Question Answering Dataset</td>\n",
              "      <td>Determine whether the context sentence containsthe answer to the question</td>\n",
              "      <td>105k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rte</th>\n",
              "      <td>Recognize Textual Entailment</td>\n",
              "      <td>Determine whether one sentece entails another</td>\n",
              "      <td>2.5k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wnli</th>\n",
              "      <td>Winograd Schema Challenge</td>\n",
              "      <td>Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>\n",
              "      <td>634</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "9LzwAiXj6WL7"
      },
      "source": [
        "As you can see some datasets are really small here. And we'll look at how one can adress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "4f3eoAHsLJAG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "N9g79wSbLJAH"
      },
      "source": [
        "Let's define main settings for the run in one place:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "7J-bVWBHLJAH"
      },
      "source": [
        "ds_name = 'glue'\n",
        "model_name = \"distilroberta-base\"\n",
        "\n",
        "max_len = 512\n",
        "bs = 32\n",
        "val_bs = bs*2\n",
        "\n",
        "n_epoch = 4\n",
        "lr = 2e-5\n",
        "wd = 0.\n",
        "opt_func = Adam\n",
        "diff_lr_decay_factor = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03T3tt0I8PA0"
      },
      "source": [
        "To make switching between datasets smooth I'll define couple of dictionaries containing per-task information. We'll need metrics, text fields to retrieve data and number of outputs for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Ekw_BmJQLJAI"
      },
      "source": [
        "GLUE_TASKS = [\"cola\", \"mnli\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
        "def validate_task():\n",
        "    assert task in GLUE_TASKS"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "tHBbTtWuLJAK"
      },
      "source": [
        "#collapse_output\n",
        "glue_metrics = {\n",
        "    'cola':[MatthewsCorrCoef()],\n",
        "    'sst2':[accuracy],\n",
        "    'mrpc':[F1Score(), accuracy],\n",
        "    'stsb':[PearsonCorrCoef(), SpearmanCorrCoef()],\n",
        "    'qqp': [F1Score(), accuracy],\n",
        "    'mnli':[accuracy],\n",
        "    'qnli':[accuracy],\n",
        "    'rte': [accuracy],\n",
        "    'wnli':[accuracy],\n",
        "}\n",
        "\n",
        "glue_textfields = {\n",
        "    'cola':['sentence', None],\n",
        "    'sst2':['sentence', None],\n",
        "    'mrpc':['sentence1', 'sentence2'],\n",
        "    'stsb':['sentence1', 'sentence2'],\n",
        "    'qqp': ['question1', 'question2'],\n",
        "    'mnli':['premise', 'hypothesis'],\n",
        "    'qnli':['question', 'sentence'],\n",
        "    'rte': ['sentence1', 'sentence2'],\n",
        "    'wnli':['sentence1', 'sentence2'],\n",
        "}\n",
        "\n",
        "glue_num_labels = {'mnli':3, 'stsb':1}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "LSfoLAjcF98s"
      },
      "source": [
        "#collapse_input\n",
        "def layerwise_splitter(model):\n",
        "    emb = L(model.base_model.embeddings)\n",
        "    layers = L(model.base_model.encoder.layer.children())\n",
        "    clf = L(m for m in list(model.children())[1:] if params(m))\n",
        "    groups = emb + layers + clf\n",
        "    return groups.map(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "s-cGTxASLJAU"
      },
      "source": [
        "## Running a GLUE task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "gI3I0hCTLJAU"
      },
      "source": [
        "#hide_output\n",
        "task = 'sst2'; validate_task()\n",
        "ds = load_dataset(ds_name, task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ49IEiqLJAV",
        "outputId": "02c56435-68a8-4312-a5a5-2df39711d766"
      },
      "source": [
        "valid_ = 'validation-matched' if task=='mnli' else 'validation'\n",
        "len(ds['train']), len(ds[valid_])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67349, 872)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNWkxjXSLJAW",
        "outputId": "c719dbca-4883-46d3-a460-267638a18d9b"
      },
      "source": [
        "train_idx, valid_idx = get_splits(ds, valid=valid_)\n",
        "train_ds = concatenate_datasets([ds['train'], ds[valid_]])\n",
        "train_ds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 0,\n",
              " 'label': 0,\n",
              " 'sentence': 'hide new secretions from the parental units '}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "AoZl29nwWR0m"
      },
      "source": [
        "Here I use number of characters a proxy for length of tokenized text to speed up `dls` creation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "5852291e134949609f1522503b45205d",
            "0fa01ff7fe3d432d8afa6806e53196df",
            "7e6487bc5a6544e0944be2beb010ba04",
            "1f59dc31d2fd45cd8bfdc6d3f38ebfb4",
            "cb4ef3b18bff4486b8871997654ec852",
            "f726ec197e184e948d40ea14e0ba41c3",
            "0eed7e356218453795d79bd17b31d21b",
            "d508a1d47d304ed8821e38038e06cc72",
            "d7715ffd7e424886a431dd79b3c8ba31",
            "89155e81544d4e49ba737cba6f9b4f99",
            "c90fde3947574cfabea146e198977ddc",
            "c05a677847ba423caa8e23a655949308",
            "99ab02879ee64d60a4c3b63c8b183eb8",
            "091e08fa4b8d43cca0cfce9bcc9a6f67",
            "e91a2643019e43f89fa414a5ae21c517",
            "8cae5a2e066d4a34b837a94958a14187"
          ]
        },
        "id": "nRdF7PzEOWPh",
        "outputId": "aeb77e0d-784a-4c34-8e76-00c6495880e1"
      },
      "source": [
        "lens = train_ds.map(lambda s: {'len': sum([len(s[i]) for i in glue_textfields[task] if i])},\n",
        "                    remove_columns=train_ds.column_names, num_proc=2, keep_in_memory=True)\n",
        "train_lens = lens.select(train_idx)['len']\n",
        "valid_lens = lens.select(valid_idx)['len']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "33Hy8rr_LJAW"
      },
      "source": [
        "blocks = [TransformersTextBlock(pretrained_model_name=model_name),CategoryBlock()]\n",
        "dblock = DataBlock(blocks=blocks,\n",
        "                   get_x=TextGetter(*glue_textfields[task]),\n",
        "                   get_y=ItemGetter('label'),\n",
        "                   splitter=IndexSplitter(valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "VCz8iyb0LJAX",
        "outputId": "afafc735-55a9-433d-d1ca-88d979d5b4b4"
      },
      "source": [
        "dl_kwargs=[{'res':train_lens}, {'val_res':valid_lens}]\n",
        "dls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs, dl_kwargs=dl_kwargs)\n",
        "dls.show_batch(max_n=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>... spiced with humor ('i speak fluent flatula,'advises denlopp after a rather, er, bubbly exchange with an alien deckhand ) and witty updatings ( silver's parrot has been replaced with morph, a cute alien creature who mimics everyone and everything around )</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stopped thinking about how good it all was, and started doing nothing but reacting to it - feeling a part of its grand locations, thinking urgently as the protagonists struggled, feeling at the mercy of its inventiveness, gasping at its visual delights.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ozpetek offers an aids subtext, skims over the realities of gay sex, and presents yet another tired old vision of the gay community as an all-inclusive world where uptight, middle class bores like antonia can feel good about themselves.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'s... worth the extra effort to see an artist, still committed to growth in his ninth decade, change while remaining true to his principles with a film whose very subject is, quite pointedly, about the peril of such efforts.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "id": "5vvw2a_TV85a"
      },
      "source": [
        "### Single run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVmV8EYlE1Ow"
      },
      "source": [
        "The GLUE benchmark contains 8 tasks and it might be cumbersome to systematize the results. To make the analysis simpler and much more powerful I will be using Weights&Biases tracking platform.\n",
        "And even better thanks to Morgan McGuire (@morg) we have an open W&B project. You just need to log your runs under `glue-benchmark` project and set `entity=\"fastai_community\"` and your results will be added to the pull for further investigation of hyperparameters. The fastest way to start participating would be to fork this notebook as it is set up to run any of the GLUE tasks with minimal changes.\n",
        "There is a lot to try: gradual unfreezing strategy is reported not to be helpful when finetuning Transformer-based models (for example see a discussion [here](https://github.com/huggingface/transformers/pull/11533)); differential learning rates are used in NLP [[1](https://arxiv.org/abs/1905.05583), [2](https://arxiv.org/abs/2003.10555)] but are not common practice, do we need to use weight decay, if yes - how much and where, what suggestions from LR-finder work best? These are only few of many open questions and there are so much more.\n",
        "And even more interesting one how do this scale with dataset and model size?\n",
        "\n",
        "Deep Learning as of now is highly empirical field and experiments require both some engeniering and compute. This post is aimed to fuel comunity effort towards finding empirical truth by joining small forces together. Even if you're new to NLP do not hasitate to participate and run couple of experiments while learning along the way!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "mYzv5FV2LJAY"
      },
      "source": [
        "WANDB_NAME = f'{ds_name}-{task}-{model_name}'\n",
        "GROUP = f'{ds_name}-{task}-{model_name}-{lr:.0e}'\n",
        "if diff_lr_decay_factor: GROUP += f\"diff_lr_{diff_lr_decay_factor}\"\n",
        "NOTES = f'finetuning {model_name} with {opt_func.__name__} lr={lr:.0e}'\n",
        "TAGS =[model_name, ds_name, opt_func.__name__]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "HpPaRBsoLJAY"
      },
      "source": [
        "#hide_output \n",
        "wandb.init(reinit=True, project=\"glue-benchmark\", entity=\"fastai_community\",\n",
        "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8f-80Y2LJAZ",
        "outputId": "e9d21a06-9d37-46e5-b749-1f655e5bf870"
      },
      "source": [
        "#hide_output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=glue_num_labels.get('task', 2))\n",
        "metrics = glue_metrics[task]\n",
        "learn = TransLearner(dls, model, metrics=metrics, opt_func=opt_func, splitter=layerwise_splitter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "eg28FJPzLJAZ",
        "outputId": "27168a24-8269-49b3-8fca-fbe2a16c9950"
      },
      "source": [
        "if diff_lr_decay_factor != 0:\n",
        "    k = len(layerwise_splitter(model))\n",
        "    lr = slice(lr*diff_lr_decay_factor**k,lr)\n",
        "\n",
        "metric_to_monitor = metrics[0].name if isinstance(metrics[0], Metric) else metrics[0].__name__\n",
        "cbs = [WandbCallback(log_preds=False, log_model=False),\n",
        "       SaveModelCallback(monitor=metric_to_monitor, fname=f'{model_name}-{task}')]\n",
        "learn.fit_one_cycle(4, lr, wd=wd, cbs=cbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not gather input dimensions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.234400</td>\n",
              "      <td>0.234248</td>\n",
              "      <td>0.915138</td>\n",
              "      <td>03:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.173527</td>\n",
              "      <td>0.247280</td>\n",
              "      <td>0.917431</td>\n",
              "      <td>03:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.097726</td>\n",
              "      <td>0.246916</td>\n",
              "      <td>0.924312</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.078707</td>\n",
              "      <td>0.263630</td>\n",
              "      <td>0.925459</td>\n",
              "      <td>03:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with accuracy value: 0.9151375889778137.\n",
            "Better model found at epoch 1 with accuracy value: 0.9174311757087708.\n",
            "Better model found at epoch 2 with accuracy value: 0.9243119359016418.\n",
            "Better model found at epoch 3 with accuracy value: 0.9254587292671204.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "nz8LGrmXLJAZ",
        "outputId": "618eba10-0c20-47f0-dccd-77aeb8f161a3"
      },
      "source": [
        "learn.show_results()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the movie has an infectious exuberance that will engage anyone with a passing interest in the skate/surf culture, the l.a. beach scene and the imaginative ( and sometimes illegal ) ways kids can make a playground out of the refuse of adults.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what really makes it special is that it pulls us into its world, gives us a hero whose suffering and triumphs we can share, surrounds him with interesting characters and sends us out of the theater feeling we've shared a great adventure.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a train wreck of an action film -- a stupefying attempt by the filmmakers to force-feed james bond into the mindless xxx mold and throw 40 years of cinematic history down the toilet in favor of bright flashes and loud bangs.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it's one of those baseball pictures where the hero is stoic, the wife is patient, the kids are as cute as all get-out and the odds against success are long enough to intimidate, but short enough to make a dream seem possible.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>though perry and hurley make inspiring efforts to breathe life into the disjointed, haphazard script by jay scherick and david ronn, neither the actors nor director reginald hudlin can make it more than fitfully entertaining.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>may be far from the best of the series, but it's assured, wonderfully respectful of its past and thrilling enough to make it abundantly clear that this movie phenomenon has once again reinvented itself for a new generation.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>despite all evidence to the contrary, this clunker has somehow managed to pose as an actual feature movie, the kind that charges full admission and gets hyped on tv and purports to amuse small children and ostensible adults.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>it's inoffensive, cheerful, built to inspire the young people, set to an unending soundtrack of beach party pop numbers and aside from its remarkable camerawork and awesome scenery, it's about as exciting as a sunburn.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>but the power of these ( subjects ) is obscured by the majority of the film that shows a stationary camera on a subject that could be mistaken for giving a public oration, rather than contributing to a film's narrative.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "xeMTwiKug9x8"
      },
      "source": [
        "#hide\n",
        "# test_dl = dls.test_dl(ds['test'])\n",
        "# preds = learn.get_preds(dl=test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "2w0SKY1bZihY"
      },
      "source": [
        "#hide\n",
        "del learn\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "id": "pJ1mof4VO3iy"
      },
      "source": [
        "### Sweeps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "ontyitQ56WMI"
      },
      "source": [
        "Finding the perfect learning rate for a task isn't easy. Add weight decay, different optimizers, differential learning rates and various scheduler to the mix and search for best hyperparameters becomes a really big task. For that reason there exist automated tools for hyperparameter search. Here we'll look at `sweep`s functionality provided by W&B.\n",
        "It not only facilitates hyperparameter finetuning but also enables great visualization of the results, which might help for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "9ykNA52vaFqV",
        "outputId": "022585a5-3f82-4ca8-9c5f-69260f447a53"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Rn6_keCAO4tR"
      },
      "source": [
        "def train():\n",
        "    with wandb.init() as run:\n",
        "        cfg = run.config\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=glue_num_labels.get(task, 2))\n",
        "        metrics = glue_metrics[task]\n",
        "        k = len(layerwise_splitter(model))\n",
        "        if cfg.diff_lr_decay_factor: lr = slice(cfg.lr*cfg.diff_lr_decay_factor**k,cfg.lr)\n",
        "        learn = TransLearner(dls, model, metrics=metrics, opt_func=Adam, splitter=layerwise_splitter)\n",
        "        learn.fit_one_cycle(n_epoch, cfg.lr, wd=cfg.wd, cbs=[WandbCallback(log_preds=False, log_model=False)])\n",
        "        del learn\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "vVtcGeAEPYTQ"
      },
      "source": [
        "metrics = glue_metrics[task]\n",
        "metric_to_monitor = metrics[0].name if isinstance(metrics[0], Metric) else metrics[0].__name__\n",
        "sweep_name = f\"glue-{task}-sweep\"\n",
        "sweep_config = {\n",
        "  \"name\": sweep_name,\n",
        "  \"method\": \"random\",\n",
        "  \"parameters\": {\n",
        "        \"lr\": {\"values\":[1e-5,2e-5,3e-5,5e-5, 1e-4, 3e-4]},\n",
        "        \"wd\":{\"values\":[0.,1e-2,5e-2]},\n",
        "        \"diff_lr_decay_factor\":{\"values\":[0., 0.9, 0.8, 0.7, 0.6]}\n",
        "    },\n",
        "  \"metric\":{\"goal\": \"maximise\", \"name\": metric_to_monitor},\n",
        "  \"early_terminate\": {\"type\": \"hyperband\", \"s\": 2, \"eta\": 3, \"max_iter\": 40}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "S06sZvmAPdDu",
        "outputId": "98494d85-2052-45d2-ce4e-c429bc811327"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='glue-benchmark', entity=\"fastai_community\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: dwio5fl2\n",
            "Sweep URL: https://wandb.ai/fastai_community/uncategorized/sweeps/dwio5fl2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "_NUFyZxIPizQ"
      },
      "source": [
        "wandb.agent(sweep_id, function=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "74Wh3zhB6WMK"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "id": "fgnpTHCjLJAu"
      },
      "source": [
        "## Another task example: MultiNLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "5cOURH1aLJAu"
      },
      "source": [
        "task = 'mnli'\n",
        "validate_task()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "egpWvJpLLJAx",
        "outputId": "90d3695e-14d2-4da6-94f2-e477c8e5ab29"
      },
      "source": [
        "ds = load_dataset(ds_name, task)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "NTCQY5HfLJAy"
      },
      "source": [
        "train_idx, valid_idx = get_splits(ds, valid='validation_matched')\n",
        "train_ds = concatenate_datasets([ds['train'], ds['validation_matched']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "6aS6Wv-YLJAy",
        "outputId": "71ad761e-9e79-4141-f9c8-3da659da1562"
      },
      "source": [
        "train_ds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hypothesis': 'Product and geography are what make cream skimming work. ',\n",
              " 'idx': 0,\n",
              " 'label': 1,\n",
              " 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "AfJJicpsLJAz",
        "outputId": "a87c8e3e-1553-423d-ff03-231344e49a5b"
      },
      "source": [
        "lens = train_ds.map(lambda s: {'len': len(s['premise'])+len(s['hypothesis'])}, remove_columns=train_ds.column_names, num_proc=4, keep_in_memory=True)\n",
        "train_lens = lens.select(train_idx)['len']\n",
        "valid_lens = lens.select(valid_idx)['len']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "1jYRVokJLJA0"
      },
      "source": [
        "dblock = DataBlock(blocks = [TransformersTextBlock(pretrained_model_name=model_name),\n",
        "                             CategoryBlock()],\n",
        "                   get_x=TextGetter(*glue_textfields[task]),\n",
        "                   get_y=ItemGetter('label'),\n",
        "                   splitter=IndexSplitter(valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "eT1s96S4LJA0",
        "outputId": "3ad6ac48-c19b-46b3-ed36-3a68cb01da1f"
      },
      "source": [
        "%%time\n",
        "dl_kwargs=[{'res':train_lens}, {'val_res':valid_lens}]\n",
        "dls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs, dl_kwargs=dl_kwargs, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 55s, sys: 2.15 s, total: 1min 57s\n",
            "Wall time: 1min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "6QFg_z2RLJA0",
        "outputId": "a159b84c-228c-4a42-e826-812f7de12b35"
      },
      "source": [
        "dls.show_batch(max_n=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>well uh that's kind of obvious i mean they're even carrying it to to where now uh that they advertise on TV you know if your if you uh you know have done this or if you need this uh uh we'll sue for you and you don't have to pay us unless you but then what they don't tell you is that if you if they win you give them at least a third of the of the thing that they win so  i don't know it is uh it's getting to be more business now rather than uh actually uh dealing with the crime than with uh um the uh punishment they the the lawyers are just in it for the money  i'm i'm convinced i know i i agree with you i think you're real you're very right that the politicians should i think they</td>\n",
              "      <td>I think that there should be an equal representation of backgrounds in our politicians.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>that's funny yeah and that is a good short term thing though that little things like that that overall though i just think we're just going to i don't know see i know i guess i'm kind of leery of this topic because i know that Bush is real for the new world order the one world government and alleviating all you know national debt between all of the nations but i see that to be a potential power problem later with um who's going to be in charge with this new world order and i you know i'm uncomfortable with that much power being in one place but i know we already have a new money system we already have new bills printed for the US Treasury already has our new bills printed for new currency and i mean i've seen them and so i know that the long-term</td>\n",
              "      <td>I hope all power is concentrated into one country.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>that's right um  we were down in Dallas right after Christmas and on the way back we stopped in Louisiana to visit my brother and we were driving my husband's Toyota pick up truck well we made a quick little stop when we got to Baton Rouge and he came came back out and the car the truck wouldn't stop i mean it wouldn't start so gave it a somebody came along and helped give it a little push and the next morning they took it to the garage and it was just a small private garage and he said it was the starter motor proba bly and he was going to take it off and either repair it or replace it or whatever and we got a call in the middle of the morning and he said i've got good news and bad news uh the starter motor</td>\n",
              "      <td>He said the starter motor was probably fine and that it must be something else.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>not really yeah really well that's pretty wild we yeah we used it for fleas we had fleas in our yard real bad last year and we did that um i just i'm not basically i like to mow the lawn believe it or not but i sometimes have problems starting the mower so a lot of times i don't get out and do it but my husband basically does most of it and he does the you know edging and all that kind of thing and we're renting and so we don't really put a lot of money into the uh you know this like this lawn could probably stand a couple of loads of dirt and some Saint Augustine we just we have winter rye out back and we have i don't even know what it is out front but um we this is the first house we've</td>\n",
              "      <td>We don't worry much about the lawn because we rent.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "qX1T4SCDVSY_"
      },
      "source": [
        "### Tracking with W&B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "PGLoRQw4VSZA"
      },
      "source": [
        "WANDB_NAME = f'{ds_name}-{task}-{model_name}'\n",
        "GROUP = f'{ds_name}-{task}-{model_name}-{lr:.0e}'\n",
        "NOTES = f'finetuning {model_name} with Adam lr={lr:.0e}'\n",
        "TAGS =[model_name, ds_name, 'adam']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "uWUub22fVSZA",
        "outputId": "78b0862f-f368-4c12-951a-fe625e82b857"
      },
      "source": [
        "#hide_output \n",
        "wandb.init(reinit=True, project=\"glue-benchmark\", entity=\"fastai_community\",\n",
        "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.29<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">glue-mnli-distilroberta-base</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/fastai_community/glue-benchmark\" target=\"_blank\">https://wandb.ai/fastai_community/glue-benchmark</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/fastai_community/glue-benchmark/runs/1qz7q5eh\" target=\"_blank\">https://wandb.ai/fastai_community/glue-benchmark/runs/1qz7q5eh</a><br/>\n",
              "                Run data is saved locally in <code>/notebooks/fasthugs/nbs/wandb/run-20210506_085458-1qz7q5eh</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "xvUv-UE9VSZA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Arlxeg8dVSZA",
        "outputId": "7a621ccb-7142-4880-d57e-020ad149c120"
      },
      "source": [
        "#hide_output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "metrics = glue_metrics[task]\n",
        "learn = TransLearner(dls, model, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "oDv3V-1VVSZA",
        "outputId": "a6c99d4d-fe55-4670-91a7-744c2d98207f"
      },
      "source": [
        "metric_to_monitor = metrics[0].name if isinstance(metrics[0], Metric) else metrics[0].__name__\n",
        "cbs = [WandbCallback(log_preds=False, log_model=False),\n",
        "       SaveModelCallback(monitor=metric_to_monitor, fname=f'{model_name}-{task}')]\n",
        "learn.fit_one_cycle(8, lr, wd=wd, cbs=cbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not gather input dimensions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/8 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1992' class='' max='12271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      16.23% [1992/12271 04:53<25:16 0.9426]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ZBjFSuy6VSZB"
      },
      "source": [
        "learn.show_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "un-sggdBVSZB"
      },
      "source": [
        "valid_mm_dl = dls.test_dl(ds['validation_mismatched'], with_labels=True)\n",
        "learn.validate(dl=valid_mm_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "4a-enhFX6WMQ"
      },
      "source": [
        "## Low resource tasks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "akrzpH2A6WMQ"
      },
      "source": [
        "Notice that `rte` task has only 2.5k samples in the training set. This is not much at all for untrivial language task like this one. But we can try to use a small trick for that. The MNLI task is quite similar and has much more training data. Let's reuse model trained on it for improving RTE score. This trick is common practice and has been employed in original [RoBERTa paper](https://arxiv.org/abs/1907.11692) whe reporting GLUE score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ApIRC0yA6WMQ",
        "outputId": "c19956b8-0636-499d-dddc-b0d802177d6d"
      },
      "source": [
        "#hide_output\n",
        "task = 'rte'; validate_task()\n",
        "\n",
        "ds = load_dataset(ds_name, task)\n",
        "\n",
        "valid_ = 'validation-matched' if task=='mnli' else 'validation'\n",
        "len(ds['train']), len(ds[valid_])\n",
        "\n",
        "train_idx, valid_idx = get_splits(ds, valid=valid_)\n",
        "train_ds = concatenate_datasets([ds['train'], ds[valid_]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/rte/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtlWrlRr6WMQ",
        "outputId": "c719dbca-4883-46d3-a460-267638a18d9b"
      },
      "source": [
        "train_ds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': 0,\n",
              " 'label': 1,\n",
              " 'sentence1': 'No Weapons of Mass Destruction Found in Iraq Yet.',\n",
              " 'sentence2': 'Weapons of Mass Destruction Found in Iraq.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "kKLK34u36WMR"
      },
      "source": [
        "dblock = DataBlock(blocks = [TransformersTextBlock(pretrained_model_name=model_name), CategoryBlock()],\n",
        "                   get_x=TextGetter(*glue_textfields[task]),\n",
        "                   get_y=ItemGetter('label'),\n",
        "                   splitter=IndexSplitter(valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "JnGWZSc36WMR",
        "outputId": "afafc735-55a9-433d-d1ca-88d979d5b4b4"
      },
      "source": [
        "dls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs)\n",
        "dls.show_batch(max_n=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n",
              "      <td>Weapons of Mass Destruction Found in Iraq.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The most recent poll carried out by NOP market research in January revealed that 61% of Britons are opposed to joining the euro.</td>\n",
              "      <td>The introduction of the euro has been opposed.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The disappearance of York University chef Claudia Lawrence is now being treated as suspected murder, North Yorkshire Police said. However detectives said they had not found any proof that the 35-year-old, who went missing on 18 March, was dead. Her father Peter Lawrence made a direct appeal to his daughter to contact him five weeks after she disappeared. His plea came at a news conference held shortly after a Â£10,000 reward was offered to help find Miss Lawrence. Crimestoppers said the sum they were offering was \"significantly higher\" than usual because of public interest in the case.</td>\n",
              "      <td>Claudia Lawrence is 35 years old.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A Continental Connection flight from Newark to Buffalo crashed into a house about four to six miles from Buffalo Niagara International Airport on Thursday night, killing 50 people, officials said. Continental Airlines Flight 3407 is a daily commuter flight from Newark Liberty International Airport in Newark, New Jersey to Buffalo, New York, operated under the Continental Connection brand by Virginia-based regional airline Colgan Air.</td>\n",
              "      <td>A daily commuter flight crashed in New York.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "81npRw8O6WMS"
      },
      "source": [
        "WANDB_NAME = f'{ds_name}-{task}-{model_name}'\n",
        "GROUP = f'{ds_name}-{task}-{model_name}-{lr:.0e}'\n",
        "if diff_lr_decay_factor: GROUP += f\"diff_lr_{diff_lr_decay_factor}\"\n",
        "NOTES = f'finetuning {model_name} with {opt_func.__name__} lr={lr:.0e}'\n",
        "TAGS =[model_name, ds_name, opt_func.__name__]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "LyZ9_Un36WMS"
      },
      "source": [
        "#hide_output \n",
        "wandb.init(reinit=True, project=\"fasthugs\", entity=\"fastai_community\",\n",
        "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5PmV4Il6WMS",
        "outputId": "e9d21a06-9d37-46e5-b749-1f655e5bf870"
      },
      "source": [
        "#hide_output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=glue_num_labels.get('task', 2))\n",
        "metrics = glue_metrics[task]\n",
        "learn = TransLearner(dls, model, metrics=metrics, opt_func=opt_func)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "AZZp5A286WMS",
        "outputId": "17567455-182b-43f5-cb93-07fc6f98dc75"
      },
      "source": [
        "try:\n",
        "    learn.load('distilroberta-base-mnli', with_opt=False, strict=False)\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error(s) in loading state_dict for RobertaForSequenceClassification:\n",
            "\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([3, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n",
            "\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "yghn09iK6WMT",
        "outputId": "27168a24-8269-49b3-8fca-fbe2a16c9950"
      },
      "source": [
        "if diff_lr_decay_factor != 0:\n",
        "    k = len(layerwise_splitter(model))\n",
        "    lr = slice(lr*diff_lr_decay_factor**k,lr)\n",
        "\n",
        "metric_to_monitor = metrics[0].name if isinstance(metrics[0], Metric) else metrics[0].__name__\n",
        "cbs = [WandbCallback(log_preds=False, log_model=False),\n",
        "       SaveModelCallback(monitor=metric_to_monitor, fname=f'{model_name}-{task}')]\n",
        "learn.fit_one_cycle(10, lr, wd=wd, cbs=cbs, pct_start=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.569979</td>\n",
              "      <td>0.565890</td>\n",
              "      <td>0.693141</td>\n",
              "      <td>00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.511280</td>\n",
              "      <td>0.529077</td>\n",
              "      <td>0.736462</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.409093</td>\n",
              "      <td>0.601690</td>\n",
              "      <td>0.743682</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.265996</td>\n",
              "      <td>0.763166</td>\n",
              "      <td>0.736462</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.171846</td>\n",
              "      <td>0.770063</td>\n",
              "      <td>0.754513</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.098103</td>\n",
              "      <td>0.922156</td>\n",
              "      <td>0.768953</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.067698</td>\n",
              "      <td>1.030401</td>\n",
              "      <td>0.761733</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.048222</td>\n",
              "      <td>1.007513</td>\n",
              "      <td>0.772563</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.034855</td>\n",
              "      <td>1.056370</td>\n",
              "      <td>0.765343</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>1.069907</td>\n",
              "      <td>0.761733</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaLVeTuEOzIM"
      },
      "source": [
        "As one can see by using this simple trick we've improved the result reported at HuggingFace [model card](https://huggingface.co/distilroberta-base#evaluation-results) by some 10%. Pretty nice, ha?\n",
        "\n",
        "Just to be sure that improvement is due to using model finetuned on `mnli` let's do another run starting from vanilla `distilroberta`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOIFsuM16_9N"
      },
      "source": [
        "#hide_output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=glue_num_labels.get('task', 2))\n",
        "metrics = glue_metrics[task]\n",
        "learn = TransLearner(dls, model, metrics=metrics, opt_func=opt_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "uAxinun26WMT",
        "outputId": "84ac85fe-2d8f-4462-f310-1336a37ee177"
      },
      "source": [
        "learn.fit_one_cycle(10, lr, wd=wd, cbs=cbs, pct_start=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.695126</td>\n",
              "      <td>0.691306</td>\n",
              "      <td>0.527076</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.692349</td>\n",
              "      <td>0.692152</td>\n",
              "      <td>0.480144</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.678994</td>\n",
              "      <td>0.641740</td>\n",
              "      <td>0.624549</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.602276</td>\n",
              "      <td>0.600447</td>\n",
              "      <td>0.671480</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.488653</td>\n",
              "      <td>0.662074</td>\n",
              "      <td>0.678700</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.377430</td>\n",
              "      <td>0.683057</td>\n",
              "      <td>0.678700</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.269494</td>\n",
              "      <td>0.967499</td>\n",
              "      <td>0.657040</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.182777</td>\n",
              "      <td>1.016970</td>\n",
              "      <td>0.685921</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.140067</td>\n",
              "      <td>1.038462</td>\n",
              "      <td>0.696751</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.113930</td>\n",
              "      <td>1.068865</td>\n",
              "      <td>0.682310</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "MoeNR4K76WMT"
      },
      "source": [
        "The same holds for STSB taks, which has 7k training samples. You can compare the results for cold and warm starts in this [report]()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "I7DyfQ3v6WMU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}