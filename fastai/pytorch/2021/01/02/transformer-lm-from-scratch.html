<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>A Transformer based Language Model from scratch | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="A Transformer based Language Model from scratch" />
<meta name="author" content="Arto" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Building transformer with simple building blocks" />
<meta property="og:description" content="Building transformer with simple building blocks" />
<link rel="canonical" href="https://arampacha.github.io/thoughtsamples/fastai/pytorch/2021/01/02/transformer-lm-from-scratch.html" />
<meta property="og:url" content="https://arampacha.github.io/thoughtsamples/fastai/pytorch/2021/01/02/transformer-lm-from-scratch.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-02T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Building transformer with simple building blocks","url":"https://arampacha.github.io/thoughtsamples/fastai/pytorch/2021/01/02/transformer-lm-from-scratch.html","@type":"BlogPosting","headline":"A Transformer based Language Model from scratch","dateModified":"2021-01-02T00:00:00-06:00","datePublished":"2021-01-02T00:00:00-06:00","author":{"@type":"Person","name":"Arto"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://arampacha.github.io/thoughtsamples/fastai/pytorch/2021/01/02/transformer-lm-from-scratch.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/thoughtsamples/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://arampacha.github.io/thoughtsamples/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/thoughtsamples/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/thoughtsamples/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/thoughtsamples/about/">About Me</a><a class="page-link" href="/thoughtsamples/search/">Search</a><a class="page-link" href="/thoughtsamples/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A Transformer based Language Model from scratch</h1><p class="page-description">Building transformer with simple building blocks</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-01-02T00:00:00-06:00" itemprop="datePublished">
        Jan 2, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Arto</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      26 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/thoughtsamples/categories/#fastai">fastai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/thoughtsamples/categories/#pytorch">pytorch</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/arampacha/thoughtsamples/tree/master/_notebooks/2021-01-02-transformer-lm-from-scratch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/thoughtsamples/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/arampacha/thoughtsamples/master?filepath=_notebooks%2F2021-01-02-transformer-lm-from-scratch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/thoughtsamples/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/arampacha/thoughtsamples/blob/master/_notebooks/2021-01-02-transformer-lm-from-scratch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/thoughtsamples/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Data">Data </a></li>
<li class="toc-entry toc-h2"><a href="#Dot-product-attention">Dot product attention </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Multihead-attention">Multihead attention </a></li>
<li class="toc-entry toc-h3"><a href="#MultiHead-Attention-Refactor">MultiHead Attention Refactor </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#More-signal">More signal </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Arranging-data">Arranging data </a></li>
<li class="toc-entry toc-h3"><a href="#Positional-encoding">Positional encoding </a></li>
<li class="toc-entry toc-h3"><a href="#Causal-Masking">Causal Masking </a></li>
<li class="toc-entry toc-h3"><a href="#Multilayer-transformer">Multilayer transformer </a></li>
<li class="toc-entry toc-h3"><a href="#Residual-connections-and-Regularization">Residual connections and Regularization </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Bonus---Generation-example">Bonus - Generation example </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Text-generation">Text generation </a></li>
<li class="toc-entry toc-h3"><a href="#Pretraining-on-larger-dataset">Pretraining on larger dataset </a></li>
<li class="toc-entry toc-h3"><a href="#Finetune-on-Carrolls'-books">Finetune on Carrolls&#39; books </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-01-02-transformer-lm-from-scratch.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="k">if</span> <span class="s1">'google.colab'</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
    <span class="o">!</span>pip install -Uqq fastai
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this notebook i'm going to construct transformer based language model from scratch starting with the simplest building blocks. This is inspired by Chapter 12 of <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders book</a> in which it's demonstrated how to create a Recurrent Neural Network. It provides a strong intuition of how RNNs relate to regular feed-forward neural nets and why certain design choices were made. Here we aim to aquire similar kind of intuition about Transfomer based architectures.</p>
<p>But as always we should start with the data to be modeled, 'cause without data any model makes no particular sense.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data">
<a class="anchor" href="#Data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data<a class="anchor-link" href="#Data"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similar to authors of the book I'll use simple Human numbers dataset which is specifically designed to prototyping model fast and straightforward. For more details on the data one can refer to the aforemantioned book chapter which is also available for free as <a href="https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb">a notebook</a> (isn't that awesome?!)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">HUMAN_NUMBERS</span><span class="p">)</span>
<span class="n">Path</span><span class="o">.</span><span class="n">BASE_PATH</span> <span class="o">=</span> <span class="n">path</span>
<span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#2) [Path('train.txt'),Path('valid.txt')]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The data consists of consecutive numbers from 1 to 9999 inclusive spelled as words.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lines</span> <span class="o">=</span> <span class="n">L</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'train.txt'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="n">lines</span> <span class="o">+=</span> <span class="n">L</span><span class="p">(</span><span class="o">*</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'valid.txt'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="n">lines</span> <span class="o">+=</span> <span class="n">L</span><span class="p">(</span><span class="o">*</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
<span class="n">lines</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#9998) ['one \n','two \n','three \n','four \n','five \n','six \n','seven \n','eight \n','nine \n','ten \n'...]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s1">' . '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">l</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
<span class="n">tokens</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="o">*</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">vocab</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
<span class="n">nums</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">word2idx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)</span>
<span class="n">nums</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#63095) [0,1,2,1,3,1,4,1,5,1...]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The task will be to predict subsequent token given preceding three. This kind of tasks when the goal is to predict next token from previous ones is called autoregresive language modeling.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">L</span><span class="p">((</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">],</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seqs</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">tensor</span><span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">]),</span> <span class="n">nums</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">seqs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">cut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seqs</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="o">.</span><span class="n">from_dsets</span><span class="p">(</span><span class="n">seqs</span><span class="p">[:</span><span class="n">cut</span><span class="p">],</span> <span class="n">seqs</span><span class="p">[</span><span class="n">cut</span><span class="p">:],</span> <span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([64, 3]), torch.Size([64]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dot-product-attention">
<a class="anchor" href="#Dot-product-attention" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dot product attention<a class="anchor-link" href="#Dot-product-attention"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/fastai/course-v3/blob/master/nbs/dl2/images/attention.png?raw=1" alt="Multi head attention"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The core idea behind Transformers is Attention. Since the release of famous paper <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> transformers has become most popular architecture for language modelling.</p>
<p>There are a lot of great resourses explaining transformers architecture. I'll list some of those I found useful and comprehensive:</p>
<ol>
<li>
<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</a> completes the original paper with code</li>
<li>
<a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Encoder_Decoder_Model.ipynb">Encoder-Decoder Model</a> notebook by huggingface gives mathemetically grounded explanation of how transformer encoder-decoder models work</li>
<li>
<a href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2</a> one of the great blogposts by Jay Alammar visualizing generative language modelling on exaple of GPT-2</li>
<li>
<a href="https://github.com/karpathy/minGPT">minGPT</a> cool repo by A. Karpathy providing clear minimal implementation of GPT model</li>
</ol>
<p>There exist multiple attention mechanisms. The particular one used in the original transformer paper is Scaled Dot Product attention.
Given query vector for particular token we will compare it with a key vector for each token in a sequence and decide how much value vectors of those will effect resulting representetion of the token of interest. One way to view this from a linguistic prospective is: a key is a question each word respondes to, value is information that word represent and a query is related to what every word was looking to combine with.</p>
<p>Mathemetically we can compute attention for all <em>q</em>, <em>k</em>, <em>v</em> in a matrix form:</p>
<p>
$$\textbf {Attention}(Q,K,V) = \textbf {softmax}({QK^T\over\sqrt d_k})V $$
</p>
<p>Note that dot product $QK^T$ results in matrix of shape (seq_len x seq_len). Then it is devided by $ \sqrt d_k$ to compensate the fact, that longer sequences will have larger dot product. $ \textbf{softmax}$ is applied to rescale the attention matrix to be betwin 0 and 1. When multiplied by $V$ it produces a matrix of the same shape as $V$ (seq_len x dv).</p>
<p>So where those <em>q</em>, <em>k</em>, <em>v</em> come from. Well that's fairly straitforward queries are culculated from the embeddings of tokens we want to find representation for by simple linear projection. Keys and values are calculated from the embeddings of context tokens. In case of self attention all of them come from the original sequence.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">,</span> <span class="n">d_v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d_v</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">d_v</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ik</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_v</span><span class="p">,</span> <span class="n">d_in</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">d_qk</span><span class="o">**-</span><span class="mf">0.5</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iq</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ik</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">iv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">q</span><span class="nd">@k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="nd">@v</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even though self attention mechanism is extremely useful it posseses limited expressive power. Essentially we are computing weighted some of the input modified by single affine transformation, shared across the whole sequence. To add more computational power to the model we can introduce fully connected feedforward network on top of the SelfAttention layer.</p>
<p>Curious reader can find detailed formal analysis of the roles of SelfAttention and FeedForward layers in transformer architecture in <a href="https://arxiv.org/pdf/1912.10077.pdf">this paper</a> by C. Yun et al.
In brief the authors state that SelfAttention layers compute precise contextual maps and FeedForward layers then assign the results of these contextual maps to the desired output values.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="n">d_in</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The output would be of shape (bs, seq_len, d) which then may be mapped to (bs, seq_len, vocab_sz) using linear layer. But we have only one target. To adress this issue we can simply do average pooling over seq_len dimention.</p>
<p>The resulting model is fairly simple:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model1</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">SelfAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model1</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([64, 30])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.004786301031708717, lr_steep=0.019054606556892395)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">5e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.023451</td>
      <td>2.183568</td>
      <td>0.416211</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.563715</td>
      <td>2.401872</td>
      <td>0.361540</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.540635</td>
      <td>1.874314</td>
      <td>0.452817</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.594812</td>
      <td>1.739459</td>
      <td>0.456145</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.614958</td>
      <td>1.713703</td>
      <td>0.468743</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To evaluete the model performance we need to compare it to some baseline. Let's see what would be the accuracy if of the model which would always predict most common token.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n</span><span class="p">,</span><span class="n">counts</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">dls</span><span class="o">.</span><span class="n">valid</span><span class="p">:</span>
    <span class="n">n</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">range_of</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span> <span class="n">counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
<span class="n">idx</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="n">idx</span><span class="o">.</span><span class="n">item</span><span class="p">()],</span> <span class="n">counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="n">n</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(29), 'thousand', 0.15165200855716662)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, always predicting "thousand" which turn out to be the most common token in the dataset would result in ~15% accuracy. Our simple transformer does much better then that. It feels promising, so let's try to improve the architecture and check if we can get better results.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multihead-attention">
<a class="anchor" href="#Multihead-attention" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multihead attention<a class="anchor-link" href="#Multihead-attention"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A structured sequence may comprise multiple distinctive kinds of relationships. Our model is forced to learn only one way in which queries, keys and values are constructed from the original token embedding. To remove this limitation we can modify attention layer include multiple heads which would correspond to extracting different kinds of relationships between tokens. The MultiHeadAttention layer consits of several heads each of those is similar to SelfAttention layer we made before. To keep computational cost of the multi-head layer we set $d_k = d_v = d_{model}/n_h$, where $n_h$ is number of heads.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">,</span> <span class="n">d_v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d_v</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">d_v</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ik</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">d_qk</span><span class="o">**-</span><span class="mf">0.5</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iq</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ik</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">iv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">q</span><span class="nd">@k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="nd">@v</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">d_qk</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">d_v</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">d_qk</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">d_qk</span><span class="p">,</span> <span class="n">d_model</span><span class="o">//</span><span class="n">n_heads</span><span class="p">)</span>
        <span class="n">d_v</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">d_v</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">SelfAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_qk</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_heads</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_v</span><span class="o">*</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">mha</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([8, 10, 64])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model2</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="mi">4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">Model2</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">5e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.177783</td>
      <td>2.223564</td>
      <td>0.332303</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.629889</td>
      <td>1.867587</td>
      <td>0.445210</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.607201</td>
      <td>1.738342</td>
      <td>0.464464</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.606301</td>
      <td>1.711135</td>
      <td>0.467316</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.592446</td>
      <td>1.708671</td>
      <td>0.467554</td>
      <td>00:04</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="MultiHead-Attention-Refactor">
<a class="anchor" href="#MultiHead-Attention-Refactor" aria-hidden="true"><span class="octicon octicon-link"></span></a>MultiHead Attention Refactor<a class="anchor-link" href="#MultiHead-Attention-Refactor"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Python <code>for</code> loops are slow, therefore it is better to refactor the MultiHeadAttention module to compute Q, K, V for all heads in batch.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">d_model</span><span class="o">%</span><span class="k">n_heads</span> == 0
        <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="c1">#d_qk, d_v = d_model//n_heads, d_model//n_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ik</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">d_model</span><span class="o">//</span><span class="n">n_heads</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="c1"># (bs,sl,d) -&gt; (bs,sl,nh,dh) -&gt; (bs,nh,sl,dh)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iq</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ik</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">q</span><span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">q</span><span class="nd">@k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">att</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># (bs, nh, sl, sl) x (bs, nh, sl, dh) -&gt; (bs, nh, sl, dh)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="c1"># back to original shape</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">Model2</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.945255</td>
      <td>2.148961</td>
      <td>0.362729</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.576766</td>
      <td>2.055920</td>
      <td>0.426432</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.599834</td>
      <td>1.934431</td>
      <td>0.443784</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.624774</td>
      <td>1.742481</td>
      <td>0.460185</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.615320</td>
      <td>1.773680</td>
      <td>0.452817</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that some speedup is observed even on such a tiny dataset and small model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="More-signal">
<a class="anchor" href="#More-signal" aria-hidden="true"><span class="octicon octicon-link"></span></a>More signal<a class="anchor-link" href="#More-signal"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similarly to the RNN case considered in the book, we can take the next step and create more signal for the model to learn from. To adapt to the modified objective we need to make couple of steps. First let's rearrange data to proper input-target pairs for the new task.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Arranging-data">
<a class="anchor" href="#Arranging-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Arranging data<a class="anchor-link" href="#Arranging-data"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Unlike RNN the tranformer is not a stateful model. This means it treats each sequence indepently and can only attend within fixed length context. This limitation was adressed by authors of <a href="https://arxiv.org/abs/1901.02860">Transformer-XL paper</a> where adding a segment-level recurrence mechanism and a novel positional encoding scheme were proposed to enable capturing long-term dependencies. I will not go into details of TransformerXL architecture here. As will shell see stateless transformer can also learn a lot about the structure of our data.</p>
<p>One thing to note in this case is that we don't need to maintain the structure of the data outside of the sequences, so we can shuffle the sequences randomly in the dataloader.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sl</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">seqs</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">tensor</span><span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">sl</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">sl</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span><span class="o">-</span><span class="n">sl</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">sl</span><span class="p">))</span>
<span class="n">cut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seqs</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="o">.</span><span class="n">from_dsets</span><span class="p">(</span><span class="n">seqs</span><span class="p">[:</span><span class="n">cut</span><span class="p">],</span> <span class="n">seqs</span><span class="p">[</span><span class="n">cut</span><span class="p">:],</span>
                             <span class="n">bs</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">yb</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([64, 16]), torch.Size([64, 16]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">L</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">o</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">seqs</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(#16) ['one','.','two','.','three','.','four','.','five','.'...],
 (#16) ['.','two','.','three','.','four','.','five','.','six'...]]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Positional-encoding">
<a class="anchor" href="#Positional-encoding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Positional encoding<a class="anchor-link" href="#Positional-encoding"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before we did average pooling over seq_len dimention. Our model didn't care about the order of the tokens at all. But actually order of the tokens in a sentence matter a lot. In our case <code>one hundred two</code> and <code>two hundred one</code> are pretty different and <code>hundred one two</code> doesn't make sense.</p>
<p>To encorporate positional information into the model authors of the transformer architecture proposed to use positional encodings in addition to regular token embeddings. Positional encodings may be learned, but it's also possible to use hardcoded encodings. For instance encodings may be composed of sin and cos.
In this way each position in a sequence will get unique vector associated with it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">'freq'</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="mf">2.</span><span class="p">)</span><span class="o">/</span><span class="n">d</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">d</span><span class="o">**</span><span class="mf">0.5</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="n">pos_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">freq</span><span class="p">)),</span>
                             <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">freq</span><span class="p">))],</span>
                            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="n">pos_enc</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">encs</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">encs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Embedding size'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Sequence length'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransformerEmbedding</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">emb_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model3</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="mi">4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">TransformerEmbedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model3</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([64, 16, 30])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss_func</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">targ</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)),</span> <span class="n">targ</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">Model3</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.059098</td>
      <td>1.966106</td>
      <td>0.244059</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.996265</td>
      <td>0.151726</td>
      <td>0.956055</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.427699</td>
      <td>0.078305</td>
      <td>0.977865</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.207902</td>
      <td>0.066726</td>
      <td>0.976481</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.116920</td>
      <td>0.074462</td>
      <td>0.974935</td>
      <td>00:01</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wow! Thats a great accuracy! So the problem is solved and we only needed one attention layer and 2 layer deep feed-forward block? Don't you feel somewhat skeptical about this result?</p>
<p>Well, you should be! Think about what we did here: the goal was to predict a target sequence, say <code>['.','two','.','three','.','four']</code> from an input <code>['one','.','two','.','three','.']</code>. These two sequences intersect on all positions except the first and the last one. So models needs to learn simply to copy input tokens starting from the second one to the outputs. In our case this will result in 15 correct predictions of total 16 positions, thats almost 94% accuracy. This makes the task very simple but not very useful to learn. To train proper autoregressive language model, as we did with RNNs, a concept of masking is to be introduced.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Causal-Masking">
<a class="anchor" href="#Causal-Masking" aria-hidden="true"><span class="octicon octicon-link"></span></a>Causal Masking<a class="anchor-link" href="#Causal-Masking"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we want to allow the model for each token to attend only to itself and those prior to it. To acomplish this we can set all the values of attention matrix above the main diagonal to $-\infty$. After softmax this values will effectively turn to 0 thus disabling attention to the "future".</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_subsequent_mask</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">sz</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">sz</span><span class="p">,</span> <span class="n">sz</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">))</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">mask</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">get_subsequent_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">mask</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAJwklEQVR4nO3dz4vc9R3H8dfLbEzcKFVoLibSpNBaRCjRoVUDHoyFtopeWrCgUC97aTWKINqL/4CIHoqwxHoxKDTmUKRYBfXQS+gmETRZC+KPGI24HqriIYn46mGnkGTTzHfd73e/M/t+PiCQnYzri7BPvjOT2c86iQCsbRf1PQBA9wgdKIDQgQIIHSiA0IECCB0ooLfQbf/S9r9tv2v7kb52NGX7Ktuv2z5q+4jt3X1vasL2OtuHbb/U95YmbF9ue5/td2zP276x702j2H5w+DXxtu3nbW/se9O5egnd9jpJf5b0K0nXSPqd7Wv62LIM30h6KMk1km6Q9IcJ2CxJuyXN9z1iGZ6S9HKSn0j6qcZ8u+0tku6XNEhyraR1ku7qd9VSfV3Rfybp3STvJTkl6QVJd/a0pZEkJ5IcGv7+Ky1+AW7pd9WF2d4q6TZJe/re0oTt70m6WdIzkpTkVJL/9LuqkSlJl9iekjQt6ZOe9yzRV+hbJH10xsfHNebRnMn2Nkk7JB3od8lIT0p6WNK3fQ9paLukBUnPDp9u7LG9qe9RF5LkY0mPSzom6YSkL5K80u+qpXgxbplsXyrpRUkPJPmy7z3/j+3bJX2W5GDfW5ZhStJ1kp5OskPS15LG+vUb21do8dHodklXStpk++5+Vy3VV+gfS7rqjI+3Dm8ba7bXazHyvUn2971nhJ2S7rD9gRafGt1i+7l+J410XNLxJP97pLRPi+GPs1slvZ9kIclpSfsl3dTzpiX6Cv1fkn5ke7vti7X44sXfetrSiG1r8bnjfJIn+t4zSpJHk2xNsk2Lf7+vJRm7K82Zknwq6SPbVw9v2iXpaI+Tmjgm6Qbb08OvkV0awxcQp/r4nyb5xvYfJf1Di69S/iXJkT62LMNOSfdIesv2m8Pb/pTk7z1uWovuk7R3eAF4T9K9Pe+5oCQHbO+TdEiL/zJzWNJsv6uWMt+mCqx9vBgHFEDoQAGEDhRA6EABhA4U0Hvotmf63rAck7ZXYvNqGPe9vYcuaaz/gs5j0vZKbF4NY713HEIH0LFO3jBzsTdko5p909FpndR6bWh03x9f/8OVzGrFwsKCNm/e3PeMZWFz98Zl78GDBz9PsmRIJ2+B3ahN+rl3tf55X537a+ufE1hLbH94vtt56A4UQOhAAYQOFEDoQAGEDhTQKPRJO4MdwNlGhj6hZ7ADOEOTK/rEncEO4GxNQp/oM9gBtPjOuOF378xI0kZNt/VpAbSgyRW90RnsSWaTDJIMmr53HcDqaBL6xJ3BDuBsIx+6T+gZ7ADO0Og5+vCHFPCDCoAJxTvjgAIIHSiA0IECCB0ogNCBAnr5scnf1S8u+m1nn/vVbzmPDmsXV3SgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwqYqOOeu9TVUdIcI41xwBUdKIDQgQIIHSiA0IECCB0ogNCBAggdKGBk6Lavsv267aO2j9jevRrDALSnyRtmvpH0UJJDti+TdND2q0mOdrwNQEtGXtGTnEhyaPj7ryTNS9rS9TAA7VnWc3Tb2yTtkHSgizEAutH4ve62L5X0oqQHknx5nj+fkTQjSRs13dpAACvX6Ipue70WI9+bZP/57pNkNskgyWC9NrS5EcAKNXnV3ZKekTSf5InuJwFoW5Mr+k5J90i6xfabw1+/7ngXgBaNfI6e5J+SvApbAHSEd8YBBRA6UAChAwUQOlAAoQMFcApsx7o6XVbihFk0xxUdKIDQgQIIHSiA0IECCB0ogNCBAggdKIDQgQIIHSiA0IECCB0ogNCBAggdKIDQgQIIHSiA0IECCB0ogNCBAggdKIDQgQIIHSiA0IECOO55gnV1lDTHSK89XNGBAggdKIDQgQIIHSiA0IECCB0ogNCBAhqHbnud7cO2X+pyEID2LeeKvlvSfFdDAHSnUei2t0q6TdKebucA6ELTK/qTkh6W9G2HWwB0ZGTotm+X9FmSgyPuN2N7zvbcaZ1sbSCAlWtyRd8p6Q7bH0h6QdIttp87905JZpMMkgzWa0PLMwGsxMjQkzyaZGuSbZLukvRakrs7XwagNfw7OlDAsr4fPckbkt7oZAmAznBFBwogdKAAQgcKIHSgAEIHCuAUWCzB6bJrD1d0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAToHFqunqdFmJE2ZH4YoOFEDoQAGEDhRA6EABhA4UQOhAAYQOFNAodNuX295n+x3b87Zv7HoYgPY0fcPMU5JeTvIb2xdLmu5wE4CWjQzd9vck3Szp95KU5JSkU93OAtCmJg/dt0takPSs7cO299je1PEuAC1qEvqUpOskPZ1kh6SvJT1y7p1sz9iesz13WidbnglgJZqEflzS8SQHhh/v02L4Z0kym2SQZLBeG9rcCGCFRoae5FNJH9m+enjTLklHO10FoFVNX3W/T9Le4Svu70m6t7tJANrWKPQkb0oadLwFQEd4ZxxQAKEDBRA6UAChAwUQOlAAoQMFcNwz1oSujpJeK8dIc0UHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwogdKAAQgcKIHSgAEIHCiB0oABCBwrgFFjgAro6XVZa3RNmuaIDBRA6UAChAwUQOlAAoQMFEDpQAKEDBTQK3faDto/Yftv287Y3dj0MQHtGhm57i6T7JQ2SXCtpnaS7uh4GoD1NH7pPSbrE9pSkaUmfdDcJQNtGhp7kY0mPSzom6YSkL5K80vUwAO1p8tD9Ckl3Stou6UpJm2zffZ77zdiesz13WifbXwrgO2vy0P1WSe8nWUhyWtJ+STede6cks0kGSQbrtaHtnQBWoEnoxyTdYHvatiXtkjTf7SwAbWryHP2ApH2SDkl6a/jfzHa8C0CLGn0/epLHJD3W8RYAHeGdcUABhA4UQOhAAYQOFEDoQAGEDhTAcc9AT7o4SvoyXXH9+W7nig4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFEDoQAGEDhRA6EABhA4UQOhAAYQOFOAk7X9Se0HShw3v/n1Jn7c+ojuTtldi82oYl70/SLL53Bs7CX05bM8lGfQ6Yhkmba/E5tUw7nt56A4UQOhAAeMQ+mzfA5Zp0vZKbF4NY7239+foALo3Dld0AB0jdKAAQgcKIHSgAEIHCvgvNs8oBzD7ki0AAAAASUVORK5CYII=%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">q</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">32</span><span class="p">)</span>
<span class="n">att_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">((</span><span class="n">q</span><span class="nd">@k</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">mask</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">att_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">());</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We should also modify the attention layer to except mask:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">d_model</span><span class="o">%</span><span class="k">n_heads</span> == 0
        <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="n">d_qk</span><span class="p">,</span> <span class="n">d_v</span> <span class="o">=</span> <span class="n">d_model</span><span class="o">//</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d_model</span><span class="o">//</span><span class="n">n_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ik</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">d_qk</span><span class="o">**-</span><span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iq</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ik</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">q</span><span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">q</span><span class="nd">@k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">att</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># (bs, nh, sl, sl) x (bs, nh, sl, dh) -&gt; (bs, nh, sl, dh)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="c1"># back to original shape</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model4</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="mi">4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">TransformerEmbedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">get_subsequent_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">Model4</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">3e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.399806</td>
      <td>2.321602</td>
      <td>0.262533</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.804210</td>
      <td>2.251197</td>
      <td>0.251709</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.559652</td>
      <td>2.320621</td>
      <td>0.282878</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.426687</td>
      <td>2.365385</td>
      <td>0.281006</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.355069</td>
      <td>2.430914</td>
      <td>0.301025</td>
      <td>00:01</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we get somewhat lower accuracy, which is expected given that the task has become more difficult. Also training loss is significantly lower than validation loss, which means the model is overfitting. Let's see if the same approaches as was taken to RNNs can help.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multilayer-transformer">
<a class="anchor" href="#Multilayer-transformer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multilayer transformer<a class="anchor-link" href="#Multilayer-transformer"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To solve a more difficult task we ussualy need a deeper model. For convenience let's make a TransformerLayer which will combine self-attention and feed-forward blocks.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransformerLayer</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">d_ff</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">causal</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">causal</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">get_subsequent_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model5</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">TransformerEmbedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">TransformerLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layer</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">Model5</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.896548</td>
      <td>2.794600</td>
      <td>0.151611</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.790987</td>
      <td>2.813897</td>
      <td>0.151774</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.769421</td>
      <td>2.791088</td>
      <td>0.151774</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.756661</td>
      <td>2.790368</td>
      <td>0.151367</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2.748009</td>
      <td>2.799597</td>
      <td>0.150960</td>
      <td>00:04</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's not good! 4 layer deep Transformer strugles to learn anything. But there are good news, this problem has been already resolved in the original transformer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Residual-connections-and-Regularization">
<a class="anchor" href="#Residual-connections-and-Regularization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Residual connections and Regularization<a class="anchor-link" href="#Residual-connections-and-Regularization"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you are familiar with ResNets the proposed solution will not surprise you much. The idea is simple yet very effective. Instead of returning modified output $f(x)$ each transformer sublayer will return $x + f(x)$. Thishow to produce  allows the original input to propagate freely through the model. So the model learns not an entirely new representation of $x$ but how to modify $x$ to add some useful information to the original representation.</p>
<p>As we modify layers to include the residual connections let's also add some regularization by inserting Dropout layers.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransformerEmbedding</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">emb_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">trunc_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">d_model</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pos_enc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another modification is to add layer normalization which is intended to improve learning dynamics of the network by reparametrising data statistics and is generally used in transformer based architectures.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">d_model</span><span class="o">%</span><span class="k">n_heads</span> == 0
        <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="n">d_qk</span><span class="p">,</span> <span class="n">d_v</span> <span class="o">=</span> <span class="n">d_model</span><span class="o">//</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d_model</span><span class="o">//</span><span class="n">n_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ik</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">d_qk</span><span class="o">**</span><span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ik</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iq</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">q</span><span class="nd">@k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">+</span> <span class="n">mask</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">att</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># (bs, nh, sl, sl) x (bs, nh, sl, dh) -&gt; (bs, nh, sl, dh)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="c1"># back to original shape</span>

        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TransformerLayer</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">d_ff</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">p_att</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">p_ff</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="n">d_ff</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p_ff</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">causal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">causal</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">get_subsequent_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model6</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
                 <span class="n">p_emb</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">p_att</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">p_ff</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">tie_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">TransformerEmbedding</span><span class="p">(</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p_emb</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">TransformerLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span>
                                                     <span class="n">p_att</span><span class="o">=</span><span class="n">p_att</span><span class="p">,</span> <span class="n">p_ff</span><span class="o">=</span><span class="n">p_ff</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layer</span><span class="p">)],</span>
                                    <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_sz</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tie_weights</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">weight</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">Model6</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.635322</td>
      <td>2.077494</td>
      <td>0.193929</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.751456</td>
      <td>1.042653</td>
      <td>0.667806</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.120504</td>
      <td>0.743249</td>
      <td>0.767822</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.825433</td>
      <td>0.797066</td>
      <td>0.733643</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.687212</td>
      <td>0.747418</td>
      <td>0.751058</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.615355</td>
      <td>0.815827</td>
      <td>0.747233</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.576437</td>
      <td>0.809159</td>
      <td>0.751302</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.557015</td>
      <td>0.823612</td>
      <td>0.744466</td>
      <td>00:02</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bonus---Generation-example">
<a class="anchor" href="#Bonus---Generation-example" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bonus - Generation example<a class="anchor-link" href="#Bonus---Generation-example"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Learning to predict numbers is great, but let's try something more fun. We can train a langyage model generate some texts. For example let's try to generate some text in style of Lewis Carroll. For this we'll fit a language model on "Alice in Wonderland" and "Through the looking glass".</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">parse_txt</span><span class="p">(</span><span class="n">fns</span><span class="p">):</span>
    <span class="n">txts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">fns</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="s1">''</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">line</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">+=</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">line</span>
                <span class="k">elif</span> <span class="n">tmp</span><span class="p">:</span>
                    <span class="n">txts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">return</span> <span class="n">txts</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="n">parse_txt</span><span class="p">([</span><span class="n">path</span><span class="o">/</span><span class="s1">'11-0.txt'</span><span class="p">,</span> <span class="n">path</span><span class="o">/</span><span class="s1">'12-0.txt'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1779</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['\ufeffCHAPTER I. Down the Rabbit-Hole',
 'Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought Alice “without pictures or conversations?”']</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CharTokenizer</span><span class="p">(</span><span class="n">Transform</span><span class="p">):</span>
    <span class="s2">"Simple charecter level tokenizer"</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="p">[</span><span class="s1">''</span><span class="p">,</span> <span class="s1">'xxbos'</span><span class="p">,</span> <span class="s1">'xxeos'</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">printable</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c2i</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="p">[(</span><span class="n">c</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)])</span>
    <span class="k">def</span> <span class="nf">encodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">add_bos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_eos</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">strt</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">c2i</span><span class="p">[</span><span class="s1">'xxbos'</span><span class="p">]]</span> <span class="k">if</span> <span class="n">add_bos</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="n">end</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">c2i</span><span class="p">[</span><span class="s1">'xxeos'</span><span class="p">]]</span> <span class="k">if</span> <span class="n">add_eos</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="n">LMTensorText</span><span class="p">(</span><span class="n">strt</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">c2i</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span> <span class="o">+</span> <span class="n">end</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">decodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">remove_special</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TitledStr</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decode_one</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]))</span>
    <span class="k">def</span> <span class="nf">decode_one</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span> <span class="k">return</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span>
        <span class="k">elif</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="k">return</span> <span class="s1">''</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab_sz</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tok</span> <span class="o">=</span> <span class="n">CharTokenizer</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">add_bos_eos</span><span class="p">(</span><span class="n">x</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">bos_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eos_id</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">bos_id</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="p">[</span><span class="n">eos_id</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">add_bos_eos</span><span class="p">(</span><span class="n">tok</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1779</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_nums</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">nums</span><span class="p">:</span> <span class="n">all_nums</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_nums</span><span class="p">[:</span><span class="mi">15</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[1, 0, 15, 20, 13, 28, 32, 17, 30, 97, 21, 78, 97, 16, 27]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tok</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">all_nums</span><span class="p">[:</span><span class="mi">100</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>chapter i. down the rabbit-hole
alice was beginning to get very tired of sitting by her sister on
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sl</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">seqs</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_nums</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">sl</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">(</span><span class="n">all_nums</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">sl</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">all_nums</span><span class="p">)</span><span class="o">-</span><span class="n">sl</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">sl</span><span class="p">))</span>
<span class="n">cut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seqs</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="o">.</span><span class="n">from_dsets</span><span class="p">(</span><span class="n">seqs</span><span class="p">[:</span><span class="n">cut</span><span class="p">],</span> <span class="n">seqs</span><span class="p">[</span><span class="n">cut</span><span class="p">:],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda'</span><span class="p">,</span>
                             <span class="n">bs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">yb</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([8, 512]), torch.Size([8, 512]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model6</span><span class="p">(</span><span class="n">tok</span><span class="o">.</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">p_emb</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">p_ff</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">tie_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">perplexity</span><span class="p">])</span><span class="o">.</span><span class="n">to_native_fp16</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.07585775852203369, lr_steep=0.6309573650360107)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mf">5e-4</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">EarlyStoppingCallback</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.207689</td>
      <td>3.014779</td>
      <td>0.187012</td>
      <td>20.384583</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.957462</td>
      <td>2.648416</td>
      <td>0.258105</td>
      <td>14.131640</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.645952</td>
      <td>2.427977</td>
      <td>0.287435</td>
      <td>11.335924</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.499318</td>
      <td>2.395460</td>
      <td>0.292887</td>
      <td>10.973244</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2.436253</td>
      <td>2.394616</td>
      <td>0.288965</td>
      <td>10.963985</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>5</td>
      <td>2.402833</td>
      <td>2.364455</td>
      <td>0.295703</td>
      <td>10.638234</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>6</td>
      <td>2.387243</td>
      <td>2.367871</td>
      <td>0.290381</td>
      <td>10.674637</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>7</td>
      <td>2.375951</td>
      <td>2.384834</td>
      <td>0.285010</td>
      <td>10.857258</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>8</td>
      <td>2.372440</td>
      <td>2.380138</td>
      <td>0.276270</td>
      <td>10.806398</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>9</td>
      <td>2.355436</td>
      <td>2.329239</td>
      <td>0.305892</td>
      <td>10.270120</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>10</td>
      <td>2.314718</td>
      <td>2.250078</td>
      <td>0.331901</td>
      <td>9.488480</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>11</td>
      <td>2.231658</td>
      <td>2.096768</td>
      <td>0.385319</td>
      <td>8.139816</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>12</td>
      <td>2.145322</td>
      <td>1.989301</td>
      <td>0.413477</td>
      <td>7.310425</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>13</td>
      <td>1.998541</td>
      <td>1.862125</td>
      <td>0.444971</td>
      <td>6.437402</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>14</td>
      <td>1.880289</td>
      <td>1.772380</td>
      <td>0.465283</td>
      <td>5.884840</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.777548</td>
      <td>1.735309</td>
      <td>0.482080</td>
      <td>5.670681</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>16</td>
      <td>1.692429</td>
      <td>1.649408</td>
      <td>0.501937</td>
      <td>5.203897</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>17</td>
      <td>1.616076</td>
      <td>1.616357</td>
      <td>0.513688</td>
      <td>5.034715</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>18</td>
      <td>1.548247</td>
      <td>1.586346</td>
      <td>0.522575</td>
      <td>4.885864</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>19</td>
      <td>1.484927</td>
      <td>1.550523</td>
      <td>0.532633</td>
      <td>4.713936</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>20</td>
      <td>1.430124</td>
      <td>1.512773</td>
      <td>0.543213</td>
      <td>4.539303</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>21</td>
      <td>1.375972</td>
      <td>1.500666</td>
      <td>0.545199</td>
      <td>4.484674</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>22</td>
      <td>1.324876</td>
      <td>1.491262</td>
      <td>0.552637</td>
      <td>4.442699</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>23</td>
      <td>1.276637</td>
      <td>1.469852</td>
      <td>0.557975</td>
      <td>4.348590</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>24</td>
      <td>1.229700</td>
      <td>1.477631</td>
      <td>0.560189</td>
      <td>4.382551</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>25</td>
      <td>1.186633</td>
      <td>1.459370</td>
      <td>0.562956</td>
      <td>4.303250</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>26</td>
      <td>1.139820</td>
      <td>1.467342</td>
      <td>0.564225</td>
      <td>4.337692</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>27</td>
      <td>1.092420</td>
      <td>1.476885</td>
      <td>0.566960</td>
      <td>4.379283</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>28</td>
      <td>1.050866</td>
      <td>1.486061</td>
      <td>0.567350</td>
      <td>4.419652</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>29</td>
      <td>1.006091</td>
      <td>1.505293</td>
      <td>0.568506</td>
      <td>4.505473</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.957875</td>
      <td>1.528569</td>
      <td>0.567106</td>
      <td>4.611572</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No improvement since epoch 25: early stopping
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Text-generation">
<a class="anchor" href="#Text-generation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text generation<a class="anchor-link" href="#Text-generation"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">expand_dim1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">top_p_filter</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
    <span class="n">sorted_logits</span><span class="p">,</span> <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">cum_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">sorted_indices_to_remove</span> <span class="o">=</span> <span class="n">cum_probs</span> <span class="o">&gt;</span> <span class="n">top_p</span>
    <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="n">sorted_indices_to_remove</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sorted_indices</span><span class="p">,</span> <span class="n">sorted_indices_to_remove</span><span class="p">)</span>
    <span class="n">logits</span><span class="p">[</span><span class="n">indices_to_remove</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'-inf'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logits</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span>
            <span class="n">max_len</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
            <span class="n">top_k</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
            <span class="n">top_p</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
            <span class="n">early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1">#need eos_idx to work</span>
            <span class="n">eos_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1">#TODO test for potential problems</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">top_p</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">expand_dim1</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">inp</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">out</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">filtered_logits</span> <span class="o">=</span> <span class="n">top_p_filter</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">filtered_logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">out</span><span class="p">,</span> <span class="n">sample</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">early_stopping</span> <span class="ow">and</span> <span class="p">(</span><span class="n">sample</span> <span class="o">==</span> <span class="n">eos_idx</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">tok</span><span class="p">(</span><span class="s1">'Alice said '</span><span class="p">),</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eos_idx</span><span class="o">=</span><span class="n">tok</span><span class="o">.</span><span class="n">c2i</span><span class="p">[</span><span class="s1">'xxeos'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tok</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Alice said in a minute turn, only purind his with it migut at in musible. i cant elp out my why yested it to like thought: i know i did it wish indeed it hope?

</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pretraining-on-larger-dataset">
<a class="anchor" href="#Pretraining-on-larger-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pretraining on larger dataset<a class="anchor-link" href="#Pretraining-on-larger-dataset"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"bookcorpus"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">'train'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

Downloading and preparing dataset bookcorpus/plain_text (download: 1.10 GiB, generated: 4.52 GiB, post-processed: Unknown size, total: 5.62 GiB) to /root/.cache/huggingface/datasets/bookcorpus/plain_text/1.0.0/af844be26c089fb64810e9f2cd841954fd8bd596d6ddd26326e4c70e2b8c96fc...

Dataset bookcorpus downloaded and prepared to /root/.cache/huggingface/datasets/bookcorpus/plain_text/1.0.0/af844be26c089fb64810e9f2cd841954fd8bd596d6ddd26326e4c70e2b8c96fc. Subsequent calls will reuse this data.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:</span><span class="mi">10_000_000</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>the half-ling book one in the fall of igneeria series kaylee soderburg copyright 2013 kaylee soderburg all rights reserved .</td>
    </tr>
    <tr>
      <th>1</th>
      <td>isbn : 1492913731 isbn-13 : 978-1492913733 for my family , who encouraged me to never stop fighting for my dreams chapter 1 summer vacations supposed to be fun , right ?</td>
    </tr>
    <tr>
      <th>2</th>
      <td>i wish i had a better answer to that question .</td>
    </tr>
    <tr>
      <th>3</th>
      <td>starlings , new york is not the place youd expect much to happen .</td>
    </tr>
    <tr>
      <th>4</th>
      <td>its a small quiet town , the kind where everyone knows your name .</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">'len'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">splits</span> <span class="o">=</span> <span class="n">range_of</span><span class="p">(</span><span class="n">df</span><span class="p">)[:</span><span class="n">cut</span><span class="p">],</span> <span class="n">range_of</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">cut</span><span class="p">:])</span>
<span class="n">tfms</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text'</span><span class="p">),</span> <span class="n">tok</span><span class="p">])</span>
<span class="n">dsets</span> <span class="o">=</span> <span class="n">Datasets</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">tfms</span><span class="o">=</span><span class="n">tfms</span><span class="p">,</span> <span class="n">dl_type</span><span class="o">=</span><span class="n">LMDataLoader</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@patch</span>
<span class="k">def</span> <span class="nf">create_item</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span><span class="n">LMDataLoader</span><span class="p">,</span> <span class="n">seq</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">seq</span><span class="o">&gt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">IndexError</span>
    <span class="n">sl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_len</span> <span class="k">if</span> <span class="n">seq</span><span class="o">//</span><span class="bp">self</span><span class="o">.</span><span class="n">bs</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span><span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span>
    <span class="n">st</span> <span class="o">=</span> <span class="p">(</span><span class="n">seq</span><span class="o">%</span><span class="k">self</span>.bs)*self.bl + (seq//self.bs)*self.seq_len
    <span class="n">txt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chunks</span><span class="p">[</span><span class="n">st</span> <span class="p">:</span> <span class="n">st</span><span class="o">+</span><span class="n">sl</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>    
    <span class="k">return</span> <span class="n">LMTensorText</span><span class="p">(</span><span class="n">txt</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span><span class="n">txt</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">dl_kwargs</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">'lens'</span><span class="p">:</span><span class="n">df</span><span class="p">[</span><span class="s1">'len'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]]},</span> <span class="p">{</span><span class="s1">'val_lens'</span><span class="p">:</span><span class="n">df</span><span class="p">[</span><span class="s1">'len'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">splits</span><span class="p">[</span><span class="mi">1</span><span class="p">]]}]</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">dl_kwargs</span><span class="o">=</span><span class="n">dl_kwargs</span><span class="p">,</span> <span class="n">shuffle_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 13min 29s, sys: 13 s, total: 13min 42s
Wall time: 13min 35s
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>text_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>im sorry .`` ah , this is katrice , the rowan queen , coming toward us . ''i said ill tell you !but she still did n't understand why he was a slave here .the sprites had come to believe by now that they were a forgotten people .thats what happened .well have to take him with us for a ways and then let him go .nick stifled the fear in him that was trying to take over .crouching down behind the stone balusters , with every nerve tingling , valeria glared down at the stealthy figure .there did seem to be shado</td>
      <td>m sorry .`` ah , this is katrice , the rowan queen , coming toward us . ''i said ill tell you !but she still did n't understand why he was a slave here .the sprites had come to believe by now that they were a forgotten people .thats what happened .well have to take him with us for a ways and then let him go .nick stifled the fear in him that was trying to take over .crouching down behind the stone balusters , with every nerve tingling , valeria glared down at the stealthy figure .there did seem to be shadow</td>
    </tr>
    <tr>
      <th>1</th>
      <td>habitants were genuine , hard working , proud and tough .sergeant colon 's view of the world was certainly changing .'we did n't want any part of it , ' the grandfather continued , heedless of his company , 'but maybe that 's just how the rhega are destined to die ... not by our own hands , our own fights .she looked enquiring , but no one took any notice of her .more land would n't save his people-they needed something else .the other got off a single shot of his .45 caliber pistol before he was clawed acr</td>
      <td>abitants were genuine , hard working , proud and tough .sergeant colon 's view of the world was certainly changing .'we did n't want any part of it , ' the grandfather continued , heedless of his company , 'but maybe that 's just how the rhega are destined to die ... not by our own hands , our own fights .she looked enquiring , but no one took any notice of her .more land would n't save his people-they needed something else .the other got off a single shot of his .45 caliber pistol before he was clawed acro</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model6</span><span class="p">(</span><span class="n">tok</span><span class="o">.</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">p_emb</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">p_ff</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">tie_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">perplexity</span><span class="p">])</span><span class="o">.</span><span class="n">to_native_fp16</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.06309573650360108, lr_steep=0.5248074531555176)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'char_bookcorpus_10m'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;fastai.learner.Learner at 0x7fa5a807e0f0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.065701</td>
      <td>1.064358</td>
      <td>0.667121</td>
      <td>2.898976</td>
      <td>4:23:52</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'char_bookcorpus_10m'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Path('/content/drive/MyDrive/char_model/char_bookcorpus_10m.pth')</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Finetune-on-Carrolls'-books">
<a class="anchor" href="#Finetune-on-Carrolls'-books" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finetune on Carrolls' books<a class="anchor-link" href="#Finetune-on-Carrolls'-books"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sl</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">seqs</span> <span class="o">=</span> <span class="n">L</span><span class="p">((</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_nums</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">sl</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">(</span><span class="n">all_nums</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">sl</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">all_nums</span><span class="p">)</span><span class="o">-</span><span class="n">sl</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">sl</span><span class="p">))</span>
<span class="n">cut</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seqs</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="o">.</span><span class="n">from_dsets</span><span class="p">(</span><span class="n">seqs</span><span class="p">[:</span><span class="n">cut</span><span class="p">],</span> <span class="n">seqs</span><span class="p">[</span><span class="n">cut</span><span class="p">:],</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cuda'</span><span class="p">,</span>
                             <span class="n">bs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model6</span><span class="p">(</span><span class="n">tok</span><span class="o">.</span><span class="n">vocab_sz</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">p_emb</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">p_ff</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">tie_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">perplexity</span><span class="p">])</span><span class="o">.</span><span class="n">to_native_fp16</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'char_bookcorpus_10m'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.03019951581954956, lr_steep=0.25118863582611084)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.744969</td>
      <td>1.472124</td>
      <td>0.618443</td>
      <td>4.358481</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.442924</td>
      <td>1.128739</td>
      <td>0.658796</td>
      <td>3.091756</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.248169</td>
      <td>1.068535</td>
      <td>0.670881</td>
      <td>2.911111</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.134621</td>
      <td>1.048366</td>
      <td>0.675764</td>
      <td>2.852986</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.058302</td>
      <td>1.044972</td>
      <td>0.678554</td>
      <td>2.843319</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.004934</td>
      <td>1.036241</td>
      <td>0.680333</td>
      <td>2.818603</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.966509</td>
      <td>1.042076</td>
      <td>0.679461</td>
      <td>2.835096</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.938987</td>
      <td>1.040590</td>
      <td>0.680507</td>
      <td>2.830886</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.920266</td>
      <td>1.035050</td>
      <td>0.681728</td>
      <td>2.815248</td>
      <td>00:08</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.907935</td>
      <td>1.037062</td>
      <td>0.681257</td>
      <td>2.820917</td>
      <td>00:08</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">generate</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">tok</span><span class="p">(</span><span class="s1">'Alice said '</span><span class="p">),</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eos_idx</span><span class="o">=</span><span class="n">tok</span><span class="o">.</span><span class="n">c2i</span><span class="p">[</span><span class="s1">'xxeos'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tok</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Alice said what you want is, why, if you cant see a little rather from people to bed their moment, when birds began drinking from behind, and offering the cart to say something, and dripping off a strange mou
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>

<script type="application/vnd.jupyter.widget-state+json">
{"0022be0dc7aa4f4f9d947589308153f8": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_b5fe978e2b204b5a986feb53c241d943", "IPY_MODEL_f61af757678d40e7b6c470ca779a0e1b"], "layout": "IPY_MODEL_5a0205b7d88a42a68d0f8d40265add8b"}}, "0a60355694ac41c3bb36988061280cd0": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: ", "description_tooltip": null, "layout": "IPY_MODEL_db53b231459c49aa9d8fcef70617ef0b", "max": 946, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_a2628b3a684444b9b3aca1c36e111516", "value": 946}}, "0ba48d9e012f457c99d9e050ee66ce19": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_0a60355694ac41c3bb36988061280cd0", "IPY_MODEL_9542a60fecc74375b59c2ef4b667c624"], "layout": "IPY_MODEL_0ff15dad1c594db7b6ed85b2d4261a63"}}, "0ff15dad1c594db7b6ed85b2d4261a63": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "13c5eb342bfd4489b067effccb6d2118": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_9fe8214a7b1941039aadf375b90373f6", "placeholder": "\u200b", "style": "IPY_MODEL_493d11cd156a4bfcb2bdc25aa21802fe", "value": " 1.18G/1.18G [03:47&lt;00:00, 5.19MB/s]"}}, "1f5d679f52bf417dac756ae3e85f864a": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_4468101700ae4bccb66bba2dd10a13d9", "IPY_MODEL_13c5eb342bfd4489b067effccb6d2118"], "layout": "IPY_MODEL_cbe70f7f0c7c4bd99bf858a1d72d63c7"}}, "201aa25469944b0b80c9363fcc4fc95f": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_55f2f9482e3042bf81cb51aa64defd18", "placeholder": "\u200b", "style": "IPY_MODEL_fa3423ee18214e89a9ff45554a5a2d21", "value": " 3.49k/? [07:00&lt;00:00, 8.30B/s]"}}, "298d60fa5cd8441f86187130f3729e73": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "2c46976452b8428da3f74d1d37267a55": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2d2bb02afe8c4309a87354fd7858e864": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_8ecda540586c4760bf94ea3eae0767d2", "IPY_MODEL_201aa25469944b0b80c9363fcc4fc95f"], "layout": "IPY_MODEL_89f78d2a56c14ceaa6b1ebba54c4feb2"}}, "4468101700ae4bccb66bba2dd10a13d9": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: 100%", "description_tooltip": null, "layout": "IPY_MODEL_abfe640017214179908de35ea38474ce", "max": 1179510242, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_a865a148857c4d1c962381692bd59857", "value": 1179510242}}, "493d11cd156a4bfcb2bdc25aa21802fe": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "55f2f9482e3042bf81cb51aa64defd18": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5a0205b7d88a42a68d0f8d40265add8b": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7571cf9691ac419fb79dad6dfaa531d1": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "789151104986470ea6b887996b5833b5": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "7977691d32f54349a98abf6008504c3e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "89f78d2a56c14ceaa6b1ebba54c4feb2": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8ecda540586c4760bf94ea3eae0767d2": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "Downloading: ", "description_tooltip": null, "layout": "IPY_MODEL_7977691d32f54349a98abf6008504c3e", "max": 1689, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_298d60fa5cd8441f86187130f3729e73", "value": 1689}}, "9542a60fecc74375b59c2ef4b667c624": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_ec9d69f76b464d54ad54fd49738e0420", "placeholder": "\u200b", "style": "IPY_MODEL_cbd787e3c17c402299963144601fb8f0", "value": " 1.67k/? [00:00&lt;00:00, 3.96kB/s]"}}, "9fe8214a7b1941039aadf375b90373f6": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a2628b3a684444b9b3aca1c36e111516": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "a865a148857c4d1c962381692bd59857": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": "initial"}}, "abfe640017214179908de35ea38474ce": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b5fe978e2b204b5a986feb53c241d943": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "info", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_febdc99b2c074afb8e1b11aa35e7fcdf", "max": 1, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_7571cf9691ac419fb79dad6dfaa531d1", "value": 1}}, "cbd787e3c17c402299963144601fb8f0": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "cbe70f7f0c7c4bd99bf858a1d72d63c7": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "db53b231459c49aa9d8fcef70617ef0b": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ec9d69f76b464d54ad54fd49738e0420": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f61af757678d40e7b6c470ca779a0e1b": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_2c46976452b8428da3f74d1d37267a55", "placeholder": "\u200b", "style": "IPY_MODEL_789151104986470ea6b887996b5833b5", "value": " 74004228/0 [10:05&lt;00:00, 122513.28 examples/s]"}}, "fa3423ee18214e89a9ff45554a5a2d21": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "febdc99b2c074afb8e1b11aa35e7fcdf": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="arampacha/thoughtsamples"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/thoughtsamples/fastai/pytorch/2021/01/02/transformer-lm-from-scratch.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/thoughtsamples/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/thoughtsamples/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/thoughtsamples/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/thoughtsamples/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/thoughtsamples/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
